{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scraping the Wikipedia data we used pywikibot, which is a Python library specifically built for this.\n",
    "1. Loop through subcategories from a base category \"Video games by year\"\n",
    "2. Filter the selected subcategories to exclude irrelevant pages like \"Video game franchises by year of introduction\"\n",
    "3. Loop through the articles in each subcategory\n",
    "4. Save the article text, category, title and URL as JSON nodes, one JSON-file per article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pywikibot\n",
    "\n",
    "def get_subcategories_from_category(category_name):\n",
    "    site = pywikibot.Site('en', 'wikipedia')\n",
    "    cat = pywikibot.Category(site, category_name)\n",
    "    pages = list(cat.subcategories())\n",
    "    return [page.title() for page in pages]\n",
    "\n",
    "def get_games_from_category(category_name):\n",
    "    site = pywikibot.Site('en', 'wikipedia')\n",
    "    cat = pywikibot.Category(site, category_name)\n",
    "    pages = list(cat.articles())\n",
    "    return pages\n",
    "\n",
    "def save_to_json(page, subcategory):\n",
    "    data = {\n",
    "        \"text\": page.text,\n",
    "        \"category\": subcategory,\n",
    "        \"title\": page.title(),\n",
    "        \"url\": page.full_url(),\n",
    "    }\n",
    "\n",
    "    directory = os.path.join('./data', subcategory.split(':')[-1])\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    filepath = os.path.join(directory, page.title().replace('/', '_') + '.json')\n",
    "    with open(filepath, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Start with the base category\n",
    "category_name = 'Category:Video games by year'\n",
    "game_categories = get_subcategories_from_category(category_name)\n",
    "\n",
    "# Go through each sub-category to get the game pages\n",
    "for game_category in game_categories:\n",
    "    # Make sure we only look at the relevant categories (avoiding 'by decade' etc.)\n",
    "    if 'video games' in game_category.lower():\n",
    "        game_pages = get_games_from_category(game_category)\n",
    "        for page in game_pages:\n",
    "            save_to_json(page, game_category.split(':')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we processed the downloaded data for easier usage with sentiment and network analysis.\n",
    "\n",
    "1. Loop through each downloaded file in each subfolder\n",
    "2. Append each page name to a new row in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_all_page_names_from_json(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data['title']\n",
    "\n",
    "base_directory = 'project/data'\n",
    "all_page_names = []\n",
    "\n",
    "# Get all page names (multithreading is used for better performance)\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(get_all_page_names_from_json, os.path.join(base_directory, subcategory, json_file))\n",
    "                for subcategory in os.listdir(base_directory)\n",
    "                for json_file in os.listdir(os.path.join(base_directory, subcategory))]\n",
    "    \n",
    "    for future in tqdm(futures, desc=\"Fetching Page Names\", unit=\"files\"):\n",
    "        all_page_names.append(future.result())\n",
    "\n",
    "# Save all page names to CSV\n",
    "with open('all_page_names.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Page Names'])\n",
    "    for page_name in all_page_names:\n",
    "        writer.writerow([page_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Iterate through all article JSONs based on the file name list in the CSV file\n",
    "4. Extract and filter out all outlinks (other articles) in the JSON\n",
    "5. Extract and insert categories as a subnode in the JSON\n",
    "6. Find the country of development, extract the name and insert it as a subnode in the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_outlinks(text):\n",
    "    links = re.findall(r'\\[\\[(?:[^|\\]]*\\|)?([^\\]]+)\\]\\]', text)\n",
    "    return [link.split('#')[0] for link in links]\n",
    "\n",
    "def extract_categories(text):\n",
    "    return re.findall(r'\\[\\[Category:(.*?)\\]\\]', text)\n",
    "\n",
    "def get_all_page_names_from_json(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data['title']\n",
    "\n",
    "# Generic function to update JSON files\n",
    "def update_json(filepath, update_func, *args):\n",
    "    with open(filepath, 'r', encoding='utf-8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    update_func(data, *args)  # Call the provided update function\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def update_json_with_country_of_development(data):\n",
    "    # Extract development based on the categories\n",
    "    countries_of_development = []\n",
    "    for category in data.get('categories', []):\n",
    "        match = re.match(r'Video games developed in (.+)', category)\n",
    "        if match:\n",
    "            country = match.group(1)\n",
    "            countries_of_development.append(country)\n",
    "    \n",
    "    # If no countries are found, set to [\"other\"]\n",
    "    data['country of development'] = countries_of_development if countries_of_development else [\"other\"]\n",
    "     \n",
    "# Specific update methods\n",
    "def filter_outlinks(data, all_page_names):\n",
    "    data['outpages'] = [link for link in extract_outlinks(data['text']) if link in all_page_names]\n",
    "\n",
    "def add_categories(data):\n",
    "    data['categories'] = extract_categories(data['text'])\n",
    "\n",
    "def load_csv_as_list(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        # Skip the header row if the CSV has one\n",
    "        next(reader, None)\n",
    "        return list(reader)\n",
    "\n",
    "base_directory = 'project/data'\n",
    "\n",
    "# Update JSON files with filtered outlinks and categories\n",
    "json_files = [os.path.join(base_directory, subcategory, json_file)\n",
    "                for subcategory in os.listdir(base_directory)\n",
    "                for json_file in os.listdir(os.path.join(base_directory, subcategory))]\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(lambda x: update_json(x, filter_outlinks, all_page_names), json_files), \n",
    "              total=len(json_files), desc=\"Filtering Outlinks\", unit=\"files\"))\n",
    "    list(tqdm(executor.map(lambda x: update_json(x, add_categories), json_files), \n",
    "              total=len(json_files), desc=\"Adding Categories\", unit=\"files\"))\n",
    "    list(tqdm(executor.map(lambda x: update_json(x, update_json_with_country_of_development), json_files), \n",
    "        total=len(json_files), desc=\"Adding country of development\", unit=\"files\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For extracting the required sections, we used the library mwparserfromhell, which is targeted for MediaWiki-style wikis, such as Wikipedia.\n",
    "\n",
    "1. Loop through all articles\n",
    "2. Iterate through article text to find headings\n",
    "3. Save the section to a dictionary node\n",
    "4. Remove references and other formatting\n",
    "5. Save all sections per article as a JSON file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import mwparserfromhell\n",
    "\n",
    "def parse_wiki_text_to_sections(wiki_text):\n",
    "    # Parse the text with mwparserfromhell\n",
    "    wikicode = mwparserfromhell.parse(wiki_text, skip_style_tags=True)\n",
    "    \n",
    "    sections_dict = {}\n",
    "    current_section = 'introduction'\n",
    "    sections_dict[current_section] = '' # Initialize the intro section\n",
    "\n",
    "    # Iterate through the parsed wiki code\n",
    "    for node in wikicode.nodes:\n",
    "        if isinstance(node, mwparserfromhell.nodes.heading.Heading):\n",
    "            # When we find a heading, set the current section to the heading's title\n",
    "            current_section = str(node.title).strip().lower()\n",
    "            sections_dict[current_section] = ''\n",
    "        else:\n",
    "            # Otherwise, append the text of this node to the current section\n",
    "            sections_dict[current_section] += str(node)\n",
    "\n",
    "    # Clean up text for each section\n",
    "    for section, text in sections_dict.items():\n",
    "        # Remove references and other unwanted parts\n",
    "        text = mwparserfromhell.parse(text).strip_code()\n",
    "        sections_dict[section] = text\n",
    "\n",
    "    return sections_dict\n",
    "\n",
    "def load_json_data_to_dict(base_directory):\n",
    "    all_data = {}  \n",
    "    for subdir, dirs, files in os.walk(base_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                filepath = os.path.join(subdir, file)\n",
    "                with open(filepath, 'r', encoding='utf-8') as json_file:\n",
    "                    data = json.load(json_file)\n",
    "                    data[\"text\"] = parse_wiki_text_to_sections(data[\"text\"])\n",
    "                    all_data[data['title']] = data\n",
    "    return all_data\n",
    "\n",
    "base_directory = './data'\n",
    "data_file = 'game_data.json'\n",
    "\n",
    "if os.path.exists(data_file):\n",
    "    with open(data_file) as f:\n",
    "        json_data_dict = json.load(f)\n",
    "else:\n",
    "    json_data_dict = load_json_data_to_dict(base_directory)\n",
    "    with open('game_data.json', 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(json_data_dict, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file containing all sections of all articles.\n",
    "data_file = '../game_data.json'\n",
    "\n",
    "with open(data_file, encoding=\"utf-8\") as f:\n",
    "    game_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram with specified parameters\n",
    "def create_histogram(data, title, xlabel, ylabel, color='tab:blue', figuresize=(10, 6)):\n",
    "    labels = list(data.keys())\n",
    "    values = list(data.values())\n",
    "\n",
    "    n_bars = len(labels)\n",
    "    figure_width = max(labels) - min(labels)\n",
    "\n",
    "    bar_width = figure_width / (1.5 * n_bars)\n",
    "\n",
    "    plt.figure(figsize=figuresize)\n",
    "    plt.bar(labels, values, color=color, edgecolor='black', width=bar_width)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import json\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# Function to get sentiment scores\n",
    "weight_neg = 0.7\n",
    "weight_compound = 1-  weight_neg \n",
    "\n",
    "def normalize_score(score, old_min, old_max, new_min, new_max):\n",
    "    return ((score - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min\n",
    "\n",
    "# Our \"violence\" score algorithm\n",
    "def get_violence_score(neg_score, pos_score, weight_neg, weight_compound):\n",
    "    # Normalize 'neg' score from [0, 1] to [-1, 1]\n",
    "    normalized_neg_score = normalize_score(neg_score, 0, 0.35, 0, 1)\n",
    "    normalized_pos_score = normalize_score(pos_score, 0, 0.3, 0, 1)\n",
    "    \n",
    "    # Calculate the weighted score\n",
    "    violence_score = normalized_neg_score * weight_neg - normalized_pos_score * weight_compound\n",
    "    \n",
    "    return violence_score\n",
    "\n",
    "# Get Vader's sentiment scores and insert them to our violence store method\n",
    "def get_sentiment_scores(data, subsections = [\"gameplay\"]):\n",
    "    sentiment_scores = {}\n",
    "    for title, content in data.items():\n",
    "        text = \"\\n\".join([content['text'][subsection] for subsection in subsections if subsection in content[\"text\"]])\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        sentiment[\"violence\"] = get_violence_score(sentiment[\"neg\"], sentiment[\"pos\"], weight_neg, weight_compound)\n",
    "        sentiment_scores[title] = sentiment\n",
    "    return sentiment_scores\n",
    "\n",
    "# Create a histogram of sentiment scores\n",
    "def create_sentiment_histograms(sentiment_data, sentiments_to_plot=None):\n",
    "    # Default to all sentiment types if none are specified\n",
    "    if sentiments_to_plot is None:\n",
    "        sentiments_to_plot = ['pos', 'neu', 'neg', 'compound']\n",
    "\n",
    "    # Determine the number of plots\n",
    "    num_plots = len(sentiments_to_plot)\n",
    "    cols = 2  # We prefer a 2-column layout\n",
    "    rows = (num_plots + 1) // cols  # Calculate rows needed\n",
    "\n",
    "    # Set up the figure for multiple subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    if rows > 1:\n",
    "        axes = axes.flatten()  # Flatten if we have more than one row\n",
    "    else:\n",
    "        axes = [axes]  # Wrap in list if only one row (i.e., 1 or 2 plots)\n",
    "\n",
    "    fig.suptitle('Sentiment Analysis Histograms')\n",
    "\n",
    "    # Plotting each requested sentiment\n",
    "    for i, sentiment in enumerate(sentiments_to_plot):\n",
    "        scores = [details[sentiment] for details in sentiment_data.values()]\n",
    "        ax = axes[i]\n",
    "        ax.hist(scores, bins=200, color='tab:blue', edgecolor='black')\n",
    "        ax.set_title(f'{sentiment.capitalize()} Sentiment Score')\n",
    "        ax.set_xlabel('Sentiment Score')\n",
    "        ax.set_ylabel('Number of Games')\n",
    "\n",
    "    # Turn off any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "def print_top_bottom_sentiment_games(sentiment_scores, key='compound', n = 10):\n",
    "    # Sorting the games based on the compound sentiment score\n",
    "    sorted_games = sorted(sentiment_scores.items(), key=lambda x: x[1][key])\n",
    "    \n",
    "    # Print the 10 most negative games\n",
    "    print(f\"{n} Most Negative Games in terms of {key} sentiment:\")\n",
    "    for game, score in sorted_games[:n]:\n",
    "        print(f\"{game}: {score}\")\n",
    "\n",
    "    print(\"\\n\") # Newline\n",
    "\n",
    "    # Print the 10 most positive games\n",
    "    print(f\"{n} Most Positive Games in terms of {key} sentiment:\")\n",
    "    for game, score in sorted_games[-n:]:\n",
    "        print(f\"{game}: {score}\")\n",
    "\n",
    "# Check if the length of a subsection is within the specified range.\n",
    "def is_subsection_length_valid(data, subsections, min_length, max_length):\n",
    "    subsection_text = \"\"\n",
    "    for subsection in subsections:\n",
    "        subsection_text += data.get('text', {}).get(subsection, \"\") + \"\\n\"\n",
    "    word_count = len(subsection_text.split())\n",
    "    return min_length <= word_count <= max_length\n",
    "\n",
    "# Count the number of entries in the game_data dictionary that have a specified subsection with a string length within the given range.\n",
    "def count_long_subsections(game_data, subsection='gameplay', min_length=0, max_length=float('inf')):\n",
    "    return sum(is_subsection_length_valid(data, subsection, min_length, max_length) for _, data in game_data.items())\n",
    "\n",
    "# Create a dictionary with only the entries from game_data that have a specified subsection with a string length within the given range.\n",
    "def filter_entries_by_length(game_data, subsections=['gameplay'], min_length=0, max_length=float('inf')):\n",
    "    return {game: data for game, data in game_data.items() if is_subsection_length_valid(data, subsections, min_length, max_length)}\n",
    "\n",
    "# Save specified data as a JSON file\n",
    "def get_or_create_value(function_to_apply, file_path):\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load the value from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            value = json.load(file)\n",
    "    else:\n",
    "        # Call the function to create the value\n",
    "        value = function_to_apply()\n",
    "        # Save the value to the file\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(value, file)\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the sentiment dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a sentiment dictionary by looping through the predefined sections in all files, then calculating the violence score in that section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints for filtering entries by length\n",
    "constrains = {\n",
    "    \"min_length\": 100,\n",
    "    \"max_length\": 10000\n",
    "}\n",
    "\n",
    "# List of subsections to filter from game_data\n",
    "subsections = ['gameplay', 'plot', 'story', 'synopsis', 'plot and gameplay', 'plot and gameplay']\n",
    "\n",
    "# Filtering entries by length based on constraints\n",
    "filtered_by_length = filter_entries_by_length(game_data, subsections=subsections, **constrains)\n",
    "\n",
    "# Getting sentiment scores for filtered entries and storing them in a JSON file\n",
    "sentiment_filtered_by_length = get_or_create_value(\n",
    "    lambda: get_sentiment_scores(filtered_by_length, subsections),\n",
    "    file_path=\"filtered_gameplay_sentiment.json\"\n",
    ")\n",
    "\n",
    "# Extracting violence scores for each game from the sentiment data\n",
    "violence = [sentiment[\"violence\"] for game, sentiment in sentiment_filtered_by_length.items()]\n",
    "\n",
    "# Normalizing violence scores between 0 and 1\n",
    "for game, sentiment in sentiment_filtered_by_length.items():\n",
    "    sentiment[\"violence\"] = normalize_score(sentiment[\"violence\"], min(violence), max(violence), 0, 1)\n",
    "\n",
    "# Creating histograms for sentiment analysis including violence\n",
    "create_sentiment_histograms(\n",
    "    sentiment_data=sentiment_filtered_by_length,\n",
    "    sentiments_to_plot=['pos', 'neu', 'neg', 'compound', \"violence\"]\n",
    ")\n",
    "\n",
    "# Adding VADER sentiment analysis results for gameplay to game_data\n",
    "game_data_with_vader_sentiment_on_gameplay = get_or_create_value(\n",
    "    lambda: {\n",
    "        game: {**data, 'sentiment': sentiment_filtered_by_length[game]}\n",
    "        for game, data in filtered_by_length.items()\n",
    "    },\n",
    "    \"game_data_with_vader_sentiment.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compares different scoring algorithms with visual graphs to find out which one is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_violence_scores(data, most_violent, least_violent):\n",
    "    # Initialize dictionaries to hold the scores for the most and least violent games\n",
    "    most_violences = {'neg': [], 'neu': [], 'pos': [], 'compound': [], \"violence\": []}\n",
    "    least_violences = {'neg': [], 'neu': [], 'pos': [], 'compound': [], \"violence\": []}\n",
    "    \n",
    "    # Helper function to calculate average of a list\n",
    "    def average(lst):\n",
    "        return sum(lst) / len(lst) if lst else 0\n",
    "    \n",
    "    # Extract scores for each game in the most and least violent games lists\n",
    "    for game in most_violent:\n",
    "        if game in data:\n",
    "            most_violences['neg'].append(data[game]['neg'])\n",
    "            most_violences['neu'].append(data[game]['neu'])\n",
    "            most_violences['pos'].append(data[game]['pos'])\n",
    "            most_violences['compound'].append(data[game]['compound'])\n",
    "            most_violences['violence'].append(data[game]['violence'])\n",
    "    \n",
    "    for game in least_violent:\n",
    "        if game in data:\n",
    "            least_violences['neg'].append(data[game]['neg'])\n",
    "            least_violences['neu'].append(data[game]['neu'])\n",
    "            least_violences['pos'].append(data[game]['pos'])\n",
    "            least_violences['compound'].append(data[game]['compound'])\n",
    "            least_violences['violence'].append(data[game]['violence'])\n",
    "    \n",
    "    # Calculate averages for both groups\n",
    "    averages = {\n",
    "        'Score': ['neg', 'neu', 'pos', 'compound', \"violence\"],\n",
    "        'Average Most Violent': [\n",
    "            average(most_violences['neg']),\n",
    "            average(most_violences['neu']),\n",
    "            average(most_violences['pos']),\n",
    "            average(most_violences['compound']),\n",
    "            average(most_violences['violence'])\n",
    "        ],\n",
    "        'Average Least Violent': [\n",
    "            average(least_violences['neg']),\n",
    "            average(least_violences['neu']),\n",
    "            average(least_violences['pos']),\n",
    "            average(least_violences['compound']),\n",
    "            average(least_violences['violence'])\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Create a DataFrame to display the table\n",
    "    df = pd.DataFrame(averages)\n",
    "    \n",
    "    # Calculate and add a column for the difference between the most and least violent scores\n",
    "    df['Difference (Most - Least)'] = df['Average Most Violent'] - df['Average Least Violent']\n",
    "    \n",
    "    return df\n",
    "\n",
    "most_violent = [\"Doom (2016 video game)\", \"Grand Theft Auto V\", \"Mortal Kombat (1992 video game)\", \"God of War (2005 video game)\", \"Manhunt (video game)\", \"Gears of War (video game)\", \"Call of Duty 4: Modern Warfare\", \"Dead Space (2008 video game)\", \"Resident Evil (1996 video game)\", \"Hotline Miami\"]\n",
    "least_violent = [\"Animal Crossing: New Horizons\", \"Stardew Valley\", \"The Sims 4\", \"Minecraft\", \"Tetris\", \"Monument Valley (video game)\", \"Super Mario Odyssey\", \"Journey (2012 video game)\", \"Katamari Damacy\", \"Fez (video game)\"]\n",
    "compare_violence_scores(sentiment_filtered_by_length, most_violent, least_violent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the production year from the category.\n",
    "import re\n",
    "for game, data in game_data.items():\n",
    "    match = re.match(r'^\\d+', data[\"category\"])\n",
    "    if match:\n",
    "        data[\"year\"] = int(match.group())\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "    data.pop(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the average and standard deviation of specified sentiment scores per year from a dataset\n",
    "def calculate_sentiment_statistics(game_data: dict, sentiment_key: str):\n",
    "    sentiment_sum_per_year = defaultdict(float)\n",
    "    count_per_year = defaultdict(int)\n",
    "\n",
    "    # Sum sentiment scores and count entries for each year\n",
    "    for game in game_data.values():\n",
    "        try:\n",
    "            year = game['year']\n",
    "            sentiment_score = game[\"sentiment\"][sentiment_key]\n",
    "            sentiment_sum_per_year[year] += sentiment_score\n",
    "            count_per_year[year] += 1\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing key in data: {e}\")\n",
    "\n",
    "    # Calculate the average sentiment score for each year\n",
    "    average_sentiment_per_year = {year: sentiment_sum_per_year[year] / count_per_year[year]\n",
    "                                  for year in sentiment_sum_per_year}\n",
    "\n",
    "    # Calculate standard deviation for each year\n",
    "    std_dev_per_year = {year: np.std([game[\"sentiment\"][sentiment_key] \n",
    "                                      for game in game_data.values() if game['year'] == year])\n",
    "                        for year in count_per_year}\n",
    "\n",
    "    return average_sentiment_per_year, std_dev_per_year\n",
    "\n",
    "def plot_violence_statistics(average_violence, std_deviation):\n",
    "    # Sort the data by year\n",
    "    sorted_years = sorted(average_violence.keys())\n",
    "    average_violences = [average_violence[year] for year in sorted_years]\n",
    "    std_devs = [std_deviation[year] for year in sorted_years]\n",
    "\n",
    "    # Plotting with enhancements\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot average violence scores with error bars\n",
    "    plt.errorbar(sorted_years, average_violences, yerr=std_devs, fmt='-o',\n",
    "                 label='Average with Std Dev', color='blue')\n",
    "\n",
    "    # Fit and plot a trend line\n",
    "    z = np.polyfit(sorted_years, average_violences, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(sorted_years, p(sorted_years), \"r--\", label='Trend Line')\n",
    "\n",
    "    # Labels and title\n",
    "    plt.title('Violence Scores Over the Years with Trend and Variability')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Violence Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "average_violence, std_deviation = calculate_sentiment_statistics(game_data, \"violence\")\n",
    "plot_violence_statistics(average_violence, std_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Extract relevant data\n",
    "country_violence_data = defaultdict(list)\n",
    "for game, details in game_data.items():\n",
    "    # We assume 'violence' scores are within a 'sentiment' sub-dictionary\n",
    "    violence_score = details[\"sentiment\"][\"violence\"]\n",
    "    for country in details[\"country of development\"]:\n",
    "        country_violence_data[country].append(violence_score)\n",
    "\n",
    "# Count the number of games per country\n",
    "game_counts = Counter({country: len(scores) for country, scores in country_violence_data.items()})\n",
    "\n",
    "# Calculate average violence score for each country with at least 100 games or is Denmark\n",
    "average_violence_scores = {}\n",
    "for country, violence_scores in country_violence_data.items():\n",
    "    if (game_counts[country] >= 100 or country == \"Denmark\") and country != \"other\":\n",
    "        average_violence_scores[country] = sum(violence_scores) / len(violence_scores)\n",
    "\n",
    "# Add all other countries to 'Others'\n",
    "other_violence_scores = []\n",
    "for country, violence_scores in country_violence_data.items():\n",
    "    if (game_counts[country] < 100 and country != \"Denmark\") or \"other\":\n",
    "        other_violence_scores.extend(violence_scores)\n",
    "if other_violence_scores:\n",
    "    average_violence_scores[\"Others\"] = sum(other_violence_scores) / len(other_violence_scores)\n",
    "\n",
    "# Calculate overall average violence score\n",
    "all_scores = [score for scores in country_violence_data.values() for score in scores]\n",
    "overall_average_violence = sum(all_scores) / len(all_scores)\n",
    "\n",
    "# Plot the average violence scores\n",
    "countries = sorted(list(average_violence_scores.keys()), key= lambda x: average_violence_scores[x]) \n",
    "averages = [average_violence_scores[country] for country in countries]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(countries, averages)\n",
    "plt.xlabel('Country of Development')\n",
    "plt.ylabel('Average Violence Score')\n",
    "plt.title('Average Violence Score by Country of Development')\n",
    "plt.xticks(rotation=90)  # Rotate country names for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
    "\n",
    "# Add a line for the overall average violence level\n",
    "plt.axhline(y=overall_average_violence, color='r', linestyle='-', label=f'Overall Average ({overall_average_violence:.2f})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods for specifically community detection parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load graph object from pickle file that we saved in lecture 4\n",
    "DIRECTED_G = pickle.load(open('../data/graph.pickle', 'rb'))\n",
    "UNDIRECTED_G = DIRECTED_G.copy().to_undirected()\n",
    "# Prune the graph\n",
    "UNDIRECTED_G = UNDIRECTED_G.subgraph(max(nx.connected_components(UNDIRECTED_G), key=len))\n",
    "\n",
    "def plot_network(graph):\n",
    "    # Visualize the graph with community colors\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos = nx.spring_layout(graph)  # or use other layout algorithms like nx.kamada_kawai_layout\n",
    "    nx.draw(graph, pos, \n",
    "            # node_color=[node_colors[node] for node in graph.nodes()], \n",
    "            edge_color='gray', style='solid', with_labels=False, node_size=5, font_size=8, width=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def others_communities(communities, others):\n",
    "    new_community = set()\n",
    "    for j in others:\n",
    "        new_community = new_community.union(communities[j])\n",
    "\n",
    "    return [comm for i, comm in enumerate(communities) if i not in others] + [new_community]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"Resolution\", \"# Communities\", \"# Significant Communities\", \"Communities\", \"Node distribution\", \"Node distribution (%)\", \"Others (%)\",\n",
    "                           \"Communities (with Others)\",\"Initial modularity\", \"'Others' modularity\"])\n",
    "\n",
    "for i in range(10):\n",
    "    # Apply the Louvain community detection algorithm\n",
    "    resolution = 0 + (i*2)*0.1\n",
    "    communities = louvain_communities(UNDIRECTED_G, resolution=resolution, seed=1234)\n",
    "    communities = sorted([comm for comm in communities], key=len, reverse=True)\n",
    "    len_communities = [len(comm) for comm in communities]\n",
    "    percentages = [100*l/sum(len_communities) for l in len_communities]\n",
    "    others = [i for i, el in enumerate(percentages) if el < 1]\n",
    "    communities_others = others_communities(communities,  others)\n",
    "    df.loc[len(df)] = {\n",
    "        \"Resolution\": resolution,\n",
    "        \"# Communities\": len(communities),\n",
    "        \"# Significant Communities\": len([l/sum(percentages) for l in percentages if l > 1]),\n",
    "        \"Communities\": communities,\n",
    "        \"Node distribution\": len_communities,\n",
    "        \"Node distribution (%)\": percentages,\n",
    "        \"Others (%)\": sum([el for i, el in enumerate(percentages) if i in others]),\n",
    "        \"Communities (with Others)\": communities_others,\n",
    "        \"Initial modularity\": nx.community.modularity(UNDIRECTED_G, communities),\n",
    "        \"'Others' modularity\": nx.community.modularity(UNDIRECTED_G, communities_others)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "def spectral_clustering(graph, n_clusters = 10):\n",
    "    # Convert the graph into an adjacency matrix\n",
    "    adj_matrix = nx.to_numpy_array(graph)\n",
    "\n",
    "    # Perform spectral clustering\n",
    "    # In practice, this should be based on the specific characteristics of the graph.\n",
    "    spectral_cluster = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', random_state=42)\n",
    "    labels = spectral_cluster.fit_predict(adj_matrix)\n",
    "\n",
    "    # Output the labels to see the community assignments\n",
    "    return labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Community Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_community_violence(community):\n",
    "    nodes_in_community = (node for node in UNDIRECTED_G if node in community)\n",
    "    sentiments = nx.get_node_attributes(UNDIRECTED_G, \"sentiment\")\n",
    "\n",
    "    return [sentiments[node]['violence'] for node in nodes_in_community if node in sentiments]\n",
    "\n",
    "from collections import Counter\n",
    "def community_genre_analysis(community):\n",
    "    nodes_in_community = [node for node in UNDIRECTED_G if node in community]\n",
    "    genres = nx.get_node_attributes(UNDIRECTED_G, \"genres\")\n",
    "    nodes_in_genre = [node for node in nodes_in_community if node in genres.keys()]\n",
    "    flatten_genres = [g  for node in nodes_in_genre for g in genres[node]]\n",
    "    counts = dict(Counter(flatten_genres))\n",
    "    total = sum(counts.values())\n",
    "    # total = len(nodes_in_genre)\n",
    "    counts = sorted(counts.items(), key=lambda k: k[1], reverse=True)\n",
    "    counts = [(i, 100*c/total) for i,c in counts]\n",
    "    return counts\n",
    "\n",
    "def get_in_degree(community):\n",
    "    return [DIRECTED_G.in_degree(node) for node in community]\n",
    "def get_out_degree(community):\n",
    "    return [DIRECTED_G.out_degree(node) for node in community]\n",
    "def get_degree(community):\n",
    "    return [UNDIRECTED_G.degree(node) for node in community]\n",
    "\n",
    "years = nx.get_node_attributes(UNDIRECTED_G, \"year\")\n",
    "\n",
    "info = dict()\n",
    "info[\"sentiment\"] = {i: np.average(get_community_violence(comm)) for i,comm in enumerate(communities)}\n",
    "info[\"sentiment_more\"] = {i: get_community_violence(comm) for i,comm in enumerate(communities)}\n",
    "info[\"year\"] = {i: np.average([years[el] for el in comm if el in years]) for i,comm in enumerate(communities)}\n",
    "info[\"year_more\"] = {i: [years[el] for el in comm if el in years] for i,comm in enumerate(communities)}\n",
    "info[\"genre\"] = {i: community_genre_analysis(comm)  for i,comm in enumerate(communities)}\n",
    "info[\"in_degree\"] = {i: get_in_degree(comm)  for i,comm in enumerate(communities)}\n",
    "info[\"out_degree\"] = {i: get_out_degree(comm)  for i,comm in enumerate(communities)}\n",
    "\n",
    "sorted_communities_by_year_indexes = [str(i) for i,_ in sorted(list(info[\"year\"].items()), key=lambda x: x[1])]\n",
    "\n",
    "def boxplot_communities(y,x, title, yscale = None):\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    # Create a boxplot\n",
    "    ax.boxplot(y, labels=x)\n",
    "\n",
    "    # Add titles and labels\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_xlabel('Categories')\n",
    "    if yscale != None:\n",
    "        ax.set_yscale('log')\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Scatter plot\n",
    "y = [info[\"year\"][int(i)] for i in sorted_communities_by_year_indexes]\n",
    "x = sorted_communities_by_year_indexes\n",
    "ax1.scatter(x, y)\n",
    "\n",
    "# Set the x-ticks to correspond to the scatter plot\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(x)\n",
    "\n",
    "# Adding titles and labels\n",
    "ax1.set_title('Average year in communities')\n",
    "ax1.set_ylabel('Values')\n",
    "ax1.set_xlabel('Community IDs')\n",
    "\n",
    "# Creating secondary x-axis for scatter plot\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "# Creating the boxplot\n",
    "box_width = 0.9\n",
    "ax2.boxplot(y, widths=box_width)\n",
    "\n",
    "# Hide the original x-axis\n",
    "ax2.set_xticks([])\n",
    "\n",
    "# Drawing vertical, discontinuous lines from x-axis to each scatter point\n",
    "for x_val, y_val in zip(x, y):\n",
    "    ax1.vlines(x_val, ymin=min(y), ymax=y_val, linestyles='dashed', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare figure\n",
    "# You can adjust the size as needed\n",
    "y = [info[\"year_more\"][int(i)] for i in sorted_communities_by_year_indexes]\n",
    "x = sorted_communities_by_year_indexes\n",
    "boxplot_communities(y,x, 'Boxplots of Communities by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "#   Perform the Kruskal-Wallis H Test\n",
    "def kruskal_wallis_test(*groups):\n",
    "    stat, p_value = stats.kruskal(*groups)\n",
    "    return stat, p_value\n",
    "\n",
    "iter_list = [int(i) for i in sorted_communities_by_year_indexes]\n",
    "results = pd.DataFrame(columns=['index'] + iter_list)\n",
    "threshold = 0.05\n",
    "for k, i in enumerate(iter_list):\n",
    "    iteration = dict()\n",
    "    iteration[\"index\"] = i\n",
    "    # for j in iter_list[0: (k+1)]:\n",
    "    #     iteration[j] = \"-\"\n",
    "    for j in iter_list[(k+1):len(iter_list)]:\n",
    "        (stat, p_value) = kruskal_wallis_test(info['in_degree'][i], info['in_degree'][j])\n",
    "        iteration[j] = \"+\" if p_value < threshold else \" \"\n",
    "    results.loc[len(results)] = iteration\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By in-degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "y = [[d for d in info[\"in_degree\"][int(i)]] for i in sorted_communities_by_year_indexes]\n",
    "x = sorted_communities_by_year_indexes\n",
    "boxplot_communities(y,x, 'Boxplots of Communities by In-degree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Violence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Scatter plot\n",
    "y = [info[\"sentiment\"][int(i)] for i in sorted_communities_by_year_indexes]\n",
    "x = sorted_communities_by_year_indexes\n",
    "ax1.scatter(x, y)\n",
    "\n",
    "# Set the x-ticks to correspond to the scatter plot\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(x)\n",
    "\n",
    "# Adding titles and labels\n",
    "ax1.set_title('Average Violence in communities')\n",
    "ax1.set_ylabel('Values')\n",
    "ax1.set_xlabel('Community IDs')\n",
    "\n",
    "# Creating secondary x-axis for scatter plot\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "# Creating the boxplot\n",
    "box_width = 0.9\n",
    "ax2.boxplot(y, widths=box_width)\n",
    "\n",
    "# Hide the original x-axis\n",
    "ax2.set_xticks([])\n",
    "\n",
    "# Drawing vertical, discontinuous lines from x-axis to each scatter point\n",
    "for x_val, y_val in zip(x, y):\n",
    "    ax1.vlines(x_val, ymin=min(y), ymax=y_val, linestyles='dashed', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare figure\n",
    "# You can adjust the size as needed\n",
    "y = [info[\"sentiment_more\"][int(i)] for i in sorted_communities_by_year_indexes]\n",
    "x = sorted_communities_by_year_indexes\n",
    "boxplot_communities(y,x, 'Boxplots of Communities by violence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_analysis():\n",
    "    genres = nx.get_node_attributes(UNDIRECTED_G, \"genres\")\n",
    "    nodes_in_genre = [node for node in UNDIRECTED_G if node in genres.keys()]\n",
    "    flatten_genres = [g  for node in nodes_in_genre for g in genres[node]]\n",
    "    counts = dict(Counter(flatten_genres))\n",
    "    # total = sum(counts.values())\n",
    "    total = len(nodes_in_genre)\n",
    "    counts = sorted(counts.items(), key=lambda k: k[1], reverse=True)\n",
    "    counts = [(i, 100*c/total) for i,c in counts]\n",
    "    return counts, len(nodes_in_genre)\n",
    "overall_prop, total_games_with_genre = genre_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def check_significant_overrepresentation(overall_proportions, community_proportions, total_games):\n",
    "    significant_genres = []\n",
    "    # total_games_in_community = sum(c for _,c in overall_proportions)\n",
    "    for genre, comm_prop in community_proportions:\n",
    "        overall_prop = next((item[1] for item in overall_proportions if item[0] == genre), None)\n",
    "        if overall_prop is None:\n",
    "            continue  # Skip if genre is not found in overall proportions\n",
    "\n",
    "        # Calculate expected and observed counts\n",
    "        expected_count = overall_prop * total_games / 100\n",
    "        observed_count = comm_prop * total_games / 100\n",
    "        contingency_table = np.array([[observed_count, total_games - observed_count],\n",
    "                                      [expected_count, total_games - expected_count]])\n",
    "\n",
    "        # Perform the chi-squared test\n",
    "        chi2, p_value = chi2_contingency(contingency_table)[:2]\n",
    "\n",
    "        if p_value < 0.05:  # Consider significance level of 0.05\n",
    "            if observed_count > expected_count:\n",
    "                representation = '+++ Overrepresented +++'\n",
    "            else:\n",
    "                representation = '--- Underrepresented ---'\n",
    "            significant_genres.append((genre, comm_prop, 100*(observed_count/expected_count-1), representation))\n",
    "\n",
    "    return sorted(significant_genres, key=lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_breakdown = pd.DataFrame(columns=[\"Community\", \"Genre\", \"Presence (%)\", \"Increase (%)\", \"Status\"])\n",
    "genres = nx.get_node_attributes(UNDIRECTED_G, \"genres\")\n",
    "max_genre_length = max(len(g) for g in genres)\n",
    "total = 0\n",
    "for i in range(len(communities)):\n",
    "    for (g,c,v,r) in significant_genres:\n",
    "        print(f\"\\t\\t{g.ljust(max_genre_length)}{round(c,2)}%\\t{round(v,2)}%\\t{r}\")\n",
    "        total += c\n",
    "        genre_breakdown.loc[len(genre_breakdown)] = {\n",
    "            \"Community\": i,\n",
    "            \"Genre\": g, \n",
    "            \"Presence (%)\": round(c,2),\n",
    "            \"Increase (%)\": round(v,2),\n",
    "            \"Status\": r\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data was categoried into different communities by sentiment, the following descriptions are what ChatGPT considered each category to represent. These descriptions are supplementary, just for visualization of possible reasons for the communities - they were not used in data analysis itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community 0\n",
    "- **Overrepresented Genres:** Immersive sims, Survival horror video games, Stealth video games, Soulslike video games, Psychological horror games, Neo-noir video games, Open-world video games, Action-adventure games, Survival video games, Art games, Sandbox games, Hack and slash games, Mystery video games, Horror video games, Beat 'em ups, Adventure games.\n",
    "    - A strong preference for narrative-driven, immersive experiences with a focus on horror, stealth, and open-world adventure.\n",
    "\n",
    "#### Community 1\n",
    "- **Overrepresented Genres:** Dress-up video games, Party video games, Educational video games, Pinball video games, Metroidvania games, Puzzle video games, Racing video games, Platformers, Action games, Action-adventure games, Shooter games, Simulation video games, Tactical role-playing video games, Art games, Hack and slash games.\n",
    "    - Diverse interests ranging from creative and social games like Dress-up and Party games to more action-oriented genres like Racing and Shooter games.\n",
    "\n",
    "#### Community 2\n",
    "- **Overrepresented Genres:** Quiz video games, Shooter games, Interactive movie video games, Pinball video games, Educational video games, Racing video games, Action games, Platformers, Puzzle video games, Sports video games, Art games, Party video games, Metroidvania games.\n",
    "    - A mix of intellectual and interactive genres, suggesting a community that enjoys both knowledge-based challenges and dynamic action games.\n",
    "\n",
    "#### Community 3\n",
    "- **Overrepresented Genres:** Social deduction video games, Battle royale games, Roguelike video games, Sandbox games, Construction and management simulation games, Non-games, Survival video games, Vehicle-building video games, Pinball video games, Strategy video games, Neo-noir video games, Simulation video games, Shooter games, Music video games, Metroidvania games, Art games, Open-world video games, Puzzle video games, Action games, Hack and slash games, Beat 'em ups, Stealth video games, Platformers.\n",
    "    - A highly eclectic mix, indicating a community with varied tastes in gaming, from strategy and simulation to fast-paced action and survival genres.\n",
    "\n",
    "#### Community 4\n",
    "- **Overrepresented Genres:** Incremental games, Tactical role-playing video games, Role-playing video games, Mystery video games, Digital tabletop games, Roguelike video games, Simulation video games, Music video games.\n",
    "    - Shows a preference for gradual progression in Incremental games, strategic depth in Tactical RPGs, and a blend of mystery and music themes.\n",
    "\n",
    "#### Community 5\n",
    "- **Overrepresented Genres:** Fighting games, Martial arts video games, Sports video games, Beat 'em ups, Digital tabletop games, Educational video games, Soulslike video games, Hack and slash games, Action games, Platformers, Shooter games, Action-adventure games.\n",
    "    - Focuses on physical and competitive gaming experiences, with an emphasis on fighting, sports, and action-packed genres.\n",
    "\n",
    "#### Community 6\n",
    "- **Overrepresented Genres:** Puzzle video games, Shooter games, Action games, Platformers, Action-adventure games, Beat 'em ups, Racing video games, Party video games, Art games, Metroidvania games.\n",
    "    - A blend of fast-paced action (Shooter, Beat 'em ups) and thoughtful gameplay (Puzzle, Metroidvania), indicating versatile gaming interests.\n",
    "\n",
    "#### Community 7\n",
    "- **Overrepresented Genres:** Soulslike video games, Horror video games, Stealth video games, Shooter games, Psychological horror games, Sandbox games, Action-adventure games, Art games, Open-world video games, Mystery video games, Neo-noir video games, Tactical role-playing video games, Hack and slash games, Beat 'em ups, Fighting games.\n",
    "    - A strong inclination towards intense and immersive experiences, particularly in the realms of horror, stealth, and action.\n",
    "\n",
    "#### Community 8\n",
    "- **Overrepresented Genres:** Racing video games, Vehicle-building video games, Simulation video games, Sandbox games, Open-world video games, Shooter games, Horror video games, Beat 'em ups, Tactical role-playing video games, Action games, Fighting games, Action-adventure games, Stealth video games, Art games, Adventure games.\n",
    "    - Enjoys a mix of high-speed Racing, in-depth Simulation, and engaging Open-world adventures, along with action-packed Shooter and Fighting games.\n",
    "\n",
    "#### Community 9\n",
    "- **Overrepresented Genres:** Shooter games, Fighting games, Stealth video games, Racing video games, Beat 'em ups, Action games, Art games, Mystery video games, Hack and slash games, Action-adventure games, Psychological horror games, Horror video games, Tactical role-playing video games.\n",
    "    - Prefers action and adventure with a blend of Shooter, Fighting, and Stealth games, complemented by Horror and Mystery genres for narrative depth.\n",
    "\n",
    "#### Community 10\n",
    "- **Overrepresented Genres:** Music video games, Puzzle video games, Shooter games, Racing video games, Beat 'em ups, Art games, Action games, Hack and slash games, Platformers, Fighting games, Action-adventure games.\n",
    "    - Shows a balance between rhythm-based Music games and high-energy genres like Racing and Shooter games, with a touch of Puzzle and Platformer elements.\n",
    "\n",
    "#### Community 11\n",
    "- **Overrepresented Genres:** Role-playing video games, Simulation video games, Incremental games, Construction and management simulation games, Tactical role-playing video games, Sandbox games, Open-world video games, Strategy video games, Immersive sims, Adventure games.\n",
    "    - A preference for complex and strategic gaming experiences in RPGs and Simulation genres, indicating a taste for depth and narrative.\n",
    "\n",
    "#### Community 12\n",
    "- **Overrepresented Genres:** Non-games, Digital tabletop games, Typing video games, Educational video games, Metroidvania games, Platformers, Action games, Strategy video games, Tactical role-playing video games, Hack and slash games.\n",
    "    - Enjoys a variety of genres from educational and strategy-based games to more dynamic action-oriented experiences.\n",
    "\n",
    "#### Community 13\n",
    "- **Overrepresented Genres:** Eroge, Typing video games, Construction and management simulation games, Music video games, Hack and slash games, Tactical role-playing video games, Mystery video games, Beat 'em ups, Shooter games, Fighting games, Role-playing video games.\n",
    "    - Diverse interests with a mix of adult-themed Eroge, rhythm-based Music games, and a range of action-packed genres like Hack and slash, and Shooter games.\n",
    "\n",
    "#### Community 14\n",
    "- **Overrepresented Genres:** Racing video games, Open-world video games, Martial arts video games, Simulation video games, Metroidvania games, Beat 'em ups.\n",
    "    - A strong preference for dynamic and immersive experiences, particularly in Racing and Open-world games, with an interest in combat-oriented genres.\n",
    "\n",
    "#### Community 15\n",
    "- **Overrepresented Genres:** Incremental games, Interactive movie video games, Puzzle video games, Strategy video games, Simulation video games, Shooter games, Art games, Music video games, Action games, Role-playing video games, Open-world video games, Hack and slash games.\n",
    "    - Enjoys a combination of thought-provoking Strategy and Simulation games with more action-focused Shooter and Hack and slash genres.\n",
    "\n",
    "#### Community 16\n",
    "- **Overrepresented Genres:** Music video games, Puzzle video games, Racing video games, Party video games, Fighting games.\n",
    "    - A blend of rhythm and strategy with Music and Puzzle games, alongside fast-paced Racing and Fighting games for a dynamic gaming experience.\n",
    "\n",
    "#### Community 17\n",
    "- **Overrepresented Genres:** Non-games, Music video games, Sandbox games, Party video games, Tactical role-playing video games, Action games, Puzzle video games, Sports video games, Action-adventure games, Hack and slash games, Horror video games, Beat 'em ups, Open-world video games.\n",
    "    - A diverse range of interests from rhythm and strategy in Music and Puzzle games to action-oriented genres like Sports, Action-adventure, and Hack and slash games.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
